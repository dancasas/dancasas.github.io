<!doctype html>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-64375-4', 'auto');
  ga('send', 'pageview');
</script>
<head><meta charset="utf-8">
	<title>SMPLitex: A Generative Model and Dataset for 3D Human Texture Estimation from Single Image
		(BMVC 2023)</title>
	<meta name="title" content="SMPLitex: A Generative Model and Dataset for 3D Human Texture Estimation from Single Image" />
	<meta name="description" content="SMPLitex: A Generative Model and Dataset for 3D Human Texture Estimation from Single Image" />
	<meta http-equiv="content-type" content="text/html; charset=UTF-8">
	<meta name="viewport" content="initial-scale=1, maximum-scale=1">

	<link rel="shortcut icon" id="favicon" href="../../favicon.png"> 
	<meta name="author" content="Dan Casas">

	<meta name="robots" content="noindex" />

	<!-- JAVASCRIPT -->	
	<script type="text/javascript" src="../../js/jquery-1.11.1.min.js"></script>
	<script type="text/javascript" src="../../js/bootstrap.min.js"></script>

	<!-- CSS -->
	<link rel="stylesheet" href="../../css/bootstrap.min.css">
	<link rel="stylesheet" href="../../css/css.css">
	<link rel="stylesheet" type="text/css" href="css/project.css" media="screen">
	<link rel="stylesheet" type="text/css" media="screen" href="css/iconize.css" />

	<!-- Docs Bootstrap: getbootstrap.com -->
</head>
<!-- Els atributs del bodi son per que el menu reflexi el lloc on estas mentre fas scroll. El offset coincideix amb el padding-top del body -->

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style>

<body id="dan" data-spy="scroll" data-target="#menu" data-offset="70">
	<!-- Les ID son per cada seccio, per que fagi scroll al fer click al menu, vindrien a ser links -->
	<section id="paper_title">
		<div class="container-fluid">
			<div class="cos col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1 col-sm-12 col-xs-12" id="top">
				<h2><b>SMPLitex: A Generative Model and Dataset for 3D Human Texture Estimation from Single Image</b></h2>	
				<h4 style="line-height:1.65;"><a href="http://dancasas.github.io" target="_blank" >Dan Casas</a> and Marc Comino Trinidad<br/>
				<i>British Machine Vision Conference (BMVC)</i>, 2023</h4><br/><br/>
				<!--
				<iframe style="display: block; margin: auto;" width="560" height="315" src="https://www.youtube.com/embed/o2KJoAhEGg8" frameborder="0" allowfullscreen></iframe>
				-->
				<div class='embed-container'><iframe src='https://www.youtube.com/embed/f01Z2H5dG-g' frameborder='0' allowfullscreen></iframe></div>
			</div>
		</div>
	</section>
	<section id="abstract">
		<div class="container-fluid">
			<div class="cos col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1 col-sm-12 col-xs-12" id="top">
				<h3>Abstract</h3>
				<p>We propose SMPLitex, a method for estimating and manipulating the complete 3D appearance of humans captured from a single image. SMPLitex builds upon the recently proposed generative models for 2D images, and extends their use to the 3D domain through pixel-to-surface correspondences computed on the input image. To this end, we first train a generative model for complete 3D human appearance, and then fit it into the input image by conditioning the generative model to the visible parts of subject. Furthermore, we propose a new dataset of high-quality human textures built by sampling SMPLitex conditioned on subject descriptions and images. We quantitatively and qualitatively evaluate our method in 3 publicly available datasets, demonstrating that SMPLitex significantly outperforms existing methods for human texture estimation while allowing for a wider variety of tasks such as editing, synthesis, and manipulation..</p>
			</div>
		</div>
	</section>
	<section id="files">
		<div class="container-fluid">
			<div class="cos col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1 col-sm-12 col-xs-12">
				<h3>Files</h3>
				<ul>
					<li class="grid">
						<div class="griditem">
							<a href="contents/vidaurre_SCA2020.pdf" target="_blank" class="imageLink"><img src="contents/vidaurre_SCA2020_thumb.jpg"></a>
							<p><a href="contents/vidaurre_SCA2020.pdf" target="_blank">Paper(10MB)</a></p><br>
				  	</div>
					</li>
				</ul>
				<br>
			</div>
		</div>
	</section>
<br/>
	<section id="bibtex">
		<div class="container-fluid">
			<div class="cos col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1 col-sm-12 col-xs-12">
				<h3>Citation</h3>
				<pre>@inproceedings {casas2023smplitex,
    title = {{SMPLitex: A Generative Model and Dataset for 3D Human Texture Estimation from Single Image}},
    author = {Casas, Dan and Comino Trinidad, Marc},
    booktitle = {British Machine Vision Conference (BMVC)},
    year = {2023}
}</pre>
				   
			</div>
		</div>
	</section>
	<br>
	<section id="images">
        <div class="container-fluid">
			<div class="cos col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1 col-sm-12 col-xs-12">
				<h3>Description and Results</h3>
				<p>Our goal is to predict the accurate 3D draping of garments, worn by any body shape, for virtual try-on purposes. We put special emphasis on the ability to cope with a large variety of garments, a feature mostly ignored by existing works since it requires a model that can deal with varying topology input. To this end, we propose a fully convolutional graph neural network approach that is able to predict the nonrigid deformations of parametric garments with arbitrary mesh topology.</p> 
				<p>
					This is an example of 4 garments fitted into a large range of bodies, deformed with our approach. Notice how the wrinkles naturally match the expected behavior of the garment, and change for each shape-garment pair.
				</p>
				<video style="width: 100%; max-width: 1080px; height: auto; filter: brightness(1.0);" autoplay loop muted playsinline>
					<source src="contents/BMVC-2023-cut-01_speed_enc.mp4" type="video/mp4">
				</video>
				<p>
					Under the hood, our novel geometric deep learning approach learns to drape 3D garments by decoupling the three different sources of deformations that condition the fit of clothing: garment type, target body shape, and material.
				</p>
				<a href="contents/pipeline.jpg"><img style="width: 100%; max-width: 720px; height: auto;" src="contents/pipeline.jpg"></a>
				<p>
					The regressor <i>R</i><sub>mean</sub> estimates the 3D mesh of the designed garment fitted into a mean body shape. Then, after a mesh topology optimization step to generate the optimal topology for the designed garment, regressors <i>R</i><sub>smooth</sub> and <i>R</i><sub>fine</sub> deform the mesh to reproduce deformations caused by the target body shape and material. Importantly, these regressors are implemented in a novel fully convolutional graph neural network (FCGNN) that is able to cope with any combination of garment, topology, and target body. Below we depict the architecture of <i>R</i><sub>smooth</sub> and <i>R</i><sub>fine</sub>, based on a U-Net and graph convolutions. 
				</p>
				<a href="contents/networks.jpg"><img style="width: 100%; max-width: 720px; height: auto;" src="contents/networks.jpg"></a>
				<p>
					Below we show a variety of our results visualized from an orbital camera.
				</p>
				<img style="width: 100%; max-width: 720px; height: auto;" src="contents/vidaurre_SCA2020_clip02_x2.gif">				
				<br/>
				<p>
					Our method is highly efficient and can be used in design applications where fast feedback is required. Below we show our  tool that allows to interactively manipulate the design parameters of the garment, and quickly visualize the fit onto arbitrary target bodies.
				</p>
				<img style="width: 100%; max-width: 720px; height: auto;" src="contents/vidaurre_clip03_merged.gif">				
				<br/>
            </div>
		</div>
	</section>
	<br>
	<section id="Acknowledgments">
		<div class="container-fluid">
			<div class="cos col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1 col-sm-12 col-xs-12">
				<h3>Acknowledgments</h3>
				Igor Santesteban was supported by the Predoctoral Training Programme of the Department of Education of the Basque Government (PRE_2019_2_0104), and Elena Garces was supported by a Torres Quevedo Fellowship (PTQ2018-009868). The work was also funded in part by the Spanish Ministry of Science (project RTI2018-098694-B-I00 VizLearning).
			</div>
		</div>
	</section>
	<br>
	<section id="contact">
		<div class="container-fluid">
			<div class="cos col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1 col-sm-12 col-xs-12">
				<h3>Contact</h3>
				Dan Casas – dan.casas@urjc.es
			</div>
		</div>
	</section>
	<footer>
		<div class="container-fluid">
			<div class="cos col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1 col-sm-12 col-xs-12">
				<br/><br/><br/>
			</div>
		</div>
	</footer>
</body>
</html>
<script type="text/javascript">    
    /* SCROLL ALS LINKS */
    $('#menu .navbar-left li a, .navbar-brand').bind('click', function(e) {
        e.preventDefault(); // Deshabilitat la acció per defecte (que és anar al link directament, i aixi hi anem fent scroll molon)
        $('html,body').animate({scrollTop: $(this.hash).offset().top - 70}, 'slow');                                                         
    });
</script>
